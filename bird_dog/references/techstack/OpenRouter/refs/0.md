title: OpenRouter
description: Authenticate and use your AI models in one place

[openrouter.ai](https://openrouter.ai/docs "Docs")

# Docs

More docs coming. In the meantime, see the [OpenAI Chat API][1], which is compatible with OpenRouter, with one exception:

### Request Body

If the `model` parameter is omitted, the user or payer's default is used. Otherwise, remember to select a value for `model` from the [supported models][2] or [API][3], and include the organization prefix. [Server-Sent Events (SSE)][4] are supported as well, to enable streaming. The SSE stream will occasionally contain a "comment" payload, which you should ignore (noted below).

If the chosen model doesn't support a request parameter (such as `functions` or `logit_bias` in non-OpenAI models, or `top_k` for OpenAI), then the parameter is ignored. The rest are forwarded to the underlying model API.

### Response Body

Responses are largely consistent with OpenAI. This means that `choices` is always an array, even if the model only returns one completion. Each choice will contain a `delta` property if a stream was requested and a `message` property otherwise. This makes it easier to use the same code for all models. Note that `finish_reason` will vary depending on the model provider.

The `model` property tells you which model was used inside the underlying API. Example:

You can use the returned `id` to query for the generation status after the request is complete:

For SSE stream, we occasionally need to send an [SSE comment][5] to indicate that OpenRouter is processing your request. This is to prevent the connection from timing out. The comment will look like this:

Comment payload can be safely ignored per the [SSE specs][6]. However you can leverage it to improve UX as needed such as by showing a dynamic loading indicator.

Some SSE client implementations might not parse the payload according to spec, which leads to an uncaught error when you `JSON.stringify` the non-JSON payloads. We recommend the following clients:

* [eventsource-parser][7]
* [OpenAI SDK][8]
* [Vercel AI SDK][9]

[1]: https://platform.openai.com/docs/api-reference/chat/create
[2]: https://openrouter.ai/docs#models
[3]: https://openrouter.ai/api/v1/models
[4]: https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events/Using_server-sent_events#event_stream_format
[5]: https://html.spec.whatwg.org/multipage/server-sent-events.html#authoring-notes
[6]: https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation
[7]: https://github.com/rexxars/eventsource-parser
[8]: https://www.npmjs.com/package/openai
[9]: https://www.npmjs.com/package/ai

