{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "CLEARML_API_ACCESS_KEY = os.getenv(\"CLEARML_API_ACCESS_KEY\")\n",
    "CLEARML_API_SECRET_KEY = os.getenv(\"CLEARML_API_SECRET_KEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "SERPAPI_API_KEY = os.getenv(\"SERPAPI_API_KEY\")\n",
    "\n",
    "missing_vars = []\n",
    "if not CLEARML_API_ACCESS_KEY:\n",
    "  missing_vars.append(\"CLEARML_API_ACCESS_KEY\")\n",
    "if not CLEARML_API_SECRET_KEY:\n",
    "  missing_vars.append(\"CLEARML_API_SECRET_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "  missing_vars.append(\"OPENAI_API_KEY\")\n",
    "if not SERPAPI_API_KEY:\n",
    "  missing_vars.append(\"SERPAPI_API_KEY\")\n",
    "\n",
    "if missing_vars:\n",
    "  print(f\"The following environment variables are missing: {', '.join(missing_vars)}\")\n",
    "else:\n",
    "  print(\"All environment variables are available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks\n",
    "https://api.python.langchain.com/en/latest/callbacks/langchain.callbacks.clearml_callback.ClearMLCallbackHandler.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks import ClearMLCallbackHandler\n",
    "\n",
    "from datetime import datetime\n",
    "from langchain.callbacks import StdOutCallbackHandler\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "# Setup and use the ClearML Callback\n",
    "clearml_callback = ClearMLCallbackHandler(\n",
    "    task_type=\"inference\",\n",
    "    project_name=\"langchain_callback_demo\",\n",
    "    task_name=\"llm\",\n",
    "    tags=[\"test\"],\n",
    "    # Change the following parameters based on the amount of detail you want tracked\n",
    "    visualize=True,\n",
    "    complexity_metrics=True,\n",
    "    stream_logs=True,\n",
    ")\n",
    "callbacks = [StdOutCallbackHandler(), clearml_callback]\n",
    "# Get the OpenAI model ready to go\n",
    "llm = OpenAI(temperature=0, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# SCENARIO 1 - LLM\n",
    "llm_result = llm.generate([\"Tell me a joke\", \"Tell me a poem\"] * 3)\n",
    "# After every generation run, use flush to make sure all the metrics\n",
    "# prompts and other output are properly saved separately\n",
    "clearml_callback.flush_tracker(langchain_asset=llm, name=\"simple_sequential\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Among others, you should see that this notebook is saved along with any git information. The model JSON that contains the used parameters is saved as an artifact, there are also console logs and under the plots section, you'll find tables that represent the flow of the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone-wLAVGjDG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
